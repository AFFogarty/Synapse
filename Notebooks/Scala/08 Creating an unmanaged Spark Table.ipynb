{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating an unmanaged (external) Spark table\n",
        "This notebook describes how to create an unmanaged (also known as external) table from Spark. \n",
        "The table is created in /datalake/cities which may exist already (so you can attach to existing data) it can be created when you insert data."
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "res6: org.apache.spark.sql.DataFrame = []"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "spark.sql(\"CREATE TABLE cities (name STRING, population INT) USING PARQUET LOCATION '/datalake/cities' OPTIONS ('compression'='snappy')\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Insert a few rows into the table using a list of values.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "res7: org.apache.spark.sql.DataFrame = []"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "spark.sql(\"INSERT INTO cities VALUES ('Seattle', 730400), ('San Francisco', 881549), ('Beijing', 21540000), ('Bangalore', 10540000)\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Retrieve values back. Click on 'Chart' below to review the visualization.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "application/json": {
              "rows": [
                [
                  "Bangalore",
                  10540000
                ],
                [
                  "Beijing",
                  21540000
                ],
                [
                  "San Francisco",
                  881549
                ],
                [
                  "Seattle",
                  730400
                ]
              ],
              "schema": [
                "name",
                "population"
              ]
            }
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "display(spark.sql(\"SELECT * FROM cities ORDER BY name\"))"
      ],
      "attachments": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Drop the table. Please note the data will remain in the data lake.\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "res9: org.apache.spark.sql.DataFrame = []"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "spark.sql(\"DROP TABLE cities\")"
      ],
      "attachments": {}
    }
  ]
}